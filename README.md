
# Old Car Price Prediction Pipeline

An end-to-end machine learning pipeline for predicting used car prices, featuring automated data collection, model training, evaluation, and deployment.

## ğŸš€ Key Features

- **Automated Data Collection**: Web crawler for collecting car listings
- **ML Pipeline**: Complete workflow from data preprocessing to model serving
- **Model Management**: MLflow integration for experiment tracking and model registry
- **API Service**: FastAPI endpoint for real-time predictions
- **Orchestration**: Airflow DAGs for scheduling and monitoring

## ğŸ—ï¸ Project Structure

```
old-car-price-prediction-pipeline/
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/                  # Airflow DAG definitions
â”‚       â”œâ”€â”€ etl_pipeline.py    # ETL workflow
â”‚       â””â”€â”€ model_pipeline.py  # ML model training 
â”‚
â”œâ”€â”€ configs/                   # Configuration files
â”‚   â””â”€â”€ config.py              # Main configuration
â”‚   â””â”€â”€ config.yaml            # Airflow configuration
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                  # FastAPI application
â”‚   â”‚   â”œâ”€â”€ main.py           # API endpoints
â”‚   â”‚   â””â”€â”€ utils.py          # API utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ crawler/              # Web crawler components
â”‚   â”‚   â”œâ”€â”€ base_crawler.py   # Base crawler class
â”‚   â”‚   â”œâ”€â”€ car_dto.py        # Data transfer objects
â”‚   â”‚   â””â”€â”€ main_crawler.py   # Crawler specific for Bonbanh.com
â”‚   â”‚
â”‚   â”œâ”€â”€ ml_pipeline/          # ML pipeline components
â”‚   â”‚   â”œâ”€â”€ base_pipeline.py  # Base pipeline class
â”‚   â”‚   â”œâ”€â”€ car_prediction_pipeline.py   # Car prediction pipeline class
â”‚   â”‚
â”‚   â”œâ”€â”€ comparer/             # Data and model comparison tools
â”‚   â””â”€â”€ logger/               # Logging configuration
â”‚   â””â”€â”€ scripts/              # Script files running pipeline
â”‚
â”œâ”€â”€ data/                     # Raw and processed data
â”œâ”€â”€ artifacts/                # Saved models and 
```

## ğŸ› ï¸ Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd old-car-price-prediction-pipeline
   ```

2. **Create and activate virtual environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   or
   uv pip install -e
   ```

## ğŸš¦ Quick Start
0. **Run tools**
  - Airflow
   ```bash
   airflow standalone
   ```
  - MLflow
   ```bash
   mlflow server --host 127.0.0.1 --port 5000 --default-artifact-root ./mlruns
   ```
   - FastAPI
   ```bash
   uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000
   ```
1. **Run the ETL pipeline**
   ```bash
   python -m src.scripts.data_extract
   python -m src.scripts.data_transform
   ```

2. **Train and evaluate models**
   ```bash
   python -m src.scripts.model_build
   python -m src.scripts.model_eval
   python -m src.scripts.model_reg
   ```

3. **Start the API server**
   ```bash
   uvicorn src.api.main:app --reload
   ```

4. **Make predictions**
   ```bash
   curl -X POST "http://localhost:8000/predict" \
        -H "Content-Type: application/json" \
        -d '{"year": 2019, "mileage": 50000, "brand": "toyota", "model": "camry"}'
   ```

## ğŸ“Š Airflow DAGs

The project includes two main DAGs:

1. **ETL Pipeline**: Handles data extraction and transformation
   - Scheduled to run daily
   - Extracts car listing data from BonBanh
   - Processes and stores the cleaned data

2. **Model Pipeline**: Manages the ML workflow
   - Trains new models
   - Evaluates model performance
   - Registers models in MLflow
   - Promotes models to production if they meet criteria

## ğŸ“ˆ MLflow Integration

Track experiments and manage models using MLflow:
- View training metrics and parameters
- Compare model performance
- Manage model versions and stages


## ğŸ“§ Contact

mailto: trongntdseb@gmail.com